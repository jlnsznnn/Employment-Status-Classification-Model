{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries and importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFC04_SEX</th>\n",
       "      <th>PUFC05_AGE</th>\n",
       "      <th>PUFC06_MSTAT</th>\n",
       "      <th>PUFC07_GRADE</th>\n",
       "      <th>PUFC09_GRADTECH</th>\n",
       "      <th>PUFC11_WORK</th>\n",
       "      <th>PUFC14_PROCC</th>\n",
       "      <th>PUFC17_NATEM</th>\n",
       "      <th>PUFC18_PNWHRS</th>\n",
       "      <th>PUFC19_PHOURS</th>\n",
       "      <th>PUFC23_PCLASS</th>\n",
       "      <th>PUFC41_WQTR</th>\n",
       "      <th>PUFNEWEMPSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Market-oriented skilled agricultural workers</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Agricultural, forestry and fishery laborers</td>\n",
       "      <td>Short-term</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Without Pay (Family owned Business)</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Single</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Agricultural, forestry and fishery laborers</td>\n",
       "      <td>Short-term</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>Private Establishment</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>High School - Second Year</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Market-oriented skilled agricultural workers</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Cleaners and helpers</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>Private Household</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92236</th>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>No grade completed</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Market-oriented skilled forestry, fishery and ...</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92237</th>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>No grade completed</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Market-oriented skilled agricultural workers</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92238</th>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Production and specialized services managers</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>Employer</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92239</th>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>Married/Living Together</td>\n",
       "      <td>College - Third Year</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Not in the Labor Force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92240</th>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Single</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Production and specialized services managers</td>\n",
       "      <td>Permanent Job</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92241 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PUFC04_SEX  PUFC05_AGE             PUFC06_MSTAT  \\\n",
       "0           Male          49  Married/Living Together   \n",
       "1         Female          61  Married/Living Together   \n",
       "2           Male          19                   Single   \n",
       "3           Male          48  Married/Living Together   \n",
       "4         Female          41  Married/Living Together   \n",
       "...          ...         ...                      ...   \n",
       "92236       Male          34  Married/Living Together   \n",
       "92237     Female          32  Married/Living Together   \n",
       "92238       Male          29  Married/Living Together   \n",
       "92239     Female          29  Married/Living Together   \n",
       "92240       Male          18                   Single   \n",
       "\n",
       "                    PUFC07_GRADE PUFC09_GRADTECH PUFC11_WORK  \\\n",
       "0           High School Graduate              No         Yes   \n",
       "1           High School Graduate              No         Yes   \n",
       "2           High School Graduate              No         Yes   \n",
       "3      High School - Second Year              No         Yes   \n",
       "4           High School Graduate              No         Yes   \n",
       "...                          ...             ...         ...   \n",
       "92236         No grade completed              No         Yes   \n",
       "92237         No grade completed              No         Yes   \n",
       "92238       High School Graduate              No         Yes   \n",
       "92239       College - Third Year              No          No   \n",
       "92240       High School Graduate              No         Yes   \n",
       "\n",
       "                                            PUFC14_PROCC   PUFC17_NATEM  \\\n",
       "0           Market-oriented skilled agricultural workers  Permanent Job   \n",
       "1            Agricultural, forestry and fishery laborers     Short-term   \n",
       "2            Agricultural, forestry and fishery laborers     Short-term   \n",
       "3           Market-oriented skilled agricultural workers  Permanent Job   \n",
       "4                                   Cleaners and helpers  Permanent Job   \n",
       "...                                                  ...            ...   \n",
       "92236  Market-oriented skilled forestry, fishery and ...  Permanent Job   \n",
       "92237       Market-oriented skilled agricultural workers  Permanent Job   \n",
       "92238       Production and specialized services managers  Permanent Job   \n",
       "92239                                            Unknown        Unknown   \n",
       "92240       Production and specialized services managers  Permanent Job   \n",
       "\n",
       "       PUFC18_PNWHRS  PUFC19_PHOURS                        PUFC23_PCLASS  \\\n",
       "0                  8             24                        Self Employed   \n",
       "1                  4              8  Without Pay (Family owned Business)   \n",
       "2                  8             24                Private Establishment   \n",
       "3                  4             20                        Self Employed   \n",
       "4                 12             72                    Private Household   \n",
       "...              ...            ...                                  ...   \n",
       "92236              5             30                        Self Employed   \n",
       "92237              4             28                        Self Employed   \n",
       "92238              8             40                             Employer   \n",
       "92239              0              0                              Unknown   \n",
       "92240              4             28                        Self Employed   \n",
       "\n",
       "      PUFC41_WQTR           PUFNEWEMPSTAT  \n",
       "0             Yes                Employed  \n",
       "1             Yes                Employed  \n",
       "2             Yes                Employed  \n",
       "3             Yes                Employed  \n",
       "4             Yes                Employed  \n",
       "...           ...                     ...  \n",
       "92236         Yes                Employed  \n",
       "92237         Yes                Employed  \n",
       "92238         Yes                Employed  \n",
       "92239     Unknown  Not in the Labor Force  \n",
       "92240         Yes                Employed  \n",
       "\n",
       "[92241 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"cleaned_data_v2.csv\") \n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PUFC04_SEX\n",
      "Female -> 0\n",
      "Male -> 1\n",
      "\n",
      "PUFC06_MSTAT\n",
      "Annulled -> 0\n",
      "Divorced/Separated -> 1\n",
      "Married/Living Together -> 2\n",
      "Single -> 3\n",
      "Unknown -> 4\n",
      "Widowed -> 5\n",
      "\n",
      "PUFC07_GRADE\n",
      "College - First Year -> 0\n",
      "College - Fourth Year -> 1\n",
      "College - Second Year -> 2\n",
      "College - Third Year -> 3\n",
      "Elementary Graduate -> 4\n",
      "Grade 1 -> 5\n",
      "Grade 2 -> 6\n",
      "Grade 3 -> 7\n",
      "Grade 4 -> 8\n",
      "Grade 5 -> 9\n",
      "Grade 6 -> 10\n",
      "High School - First Year -> 11\n",
      "High School - Second Year -> 12\n",
      "High School - Third Year -> 13\n",
      "High School Graduate -> 14\n",
      "No grade completed -> 15\n",
      "Post Baccalaureate -> 16\n",
      "Post Secondary - First Year -> 17\n",
      "Post Secondary - Second Year -> 18\n",
      "Preschool -> 19\n",
      "Unknown -> 20\n",
      "\n",
      "PUFC09_GRADTECH\n",
      "No -> 0\n",
      "Yes -> 1\n",
      "\n",
      "PUFC11_WORK\n",
      "No -> 0\n",
      "Yes -> 1\n",
      "\n",
      "PUFC14_PROCC\n",
      "Administrative and commercial managers -> 0\n",
      "Agricultural, forestry and fishery laborers -> 1\n",
      "Armed forces occupations, other ranks -> 2\n",
      "Assemblers -> 3\n",
      "Building and related trades workers, excluding electricians -> 4\n",
      "Business and administration associate professionals -> 5\n",
      "Business and administration professionals -> 6\n",
      "Chief executives, senior officials and legislators -> 7\n",
      "Cleaners and helpers -> 8\n",
      "Commissioned armed forces officers -> 9\n",
      "Customer service clerks -> 10\n",
      "Drivers and mobile plant operators -> 11\n",
      "Electrical and electronics trades workers -> 12\n",
      "Food preparation assistants -> 13\n",
      "Food processing, wood working, garment and other craft and related trades workers -> 14\n",
      "General and keyboard clerks -> 15\n",
      "Handicraft and printing workers -> 16\n",
      "Health associate professionals -> 17\n",
      "Health professionals -> 18\n",
      "Hospitality, retail and other services managers -> 19\n",
      "Information and communication technology professionals -> 20\n",
      "Information and communications technician -> 21\n",
      "Laborers in mining, construction, manufacturing and transport -> 22\n",
      "Legal, social and cultural professionals -> 23\n",
      "Legal, social, cultural and related professionals -> 24\n",
      "Market-oriented skilled agricultural workers -> 25\n",
      "Market-oriented skilled forestry, fishery and hunting workers -> 26\n",
      "Metal, machinery and related trades workers -> 27\n",
      "Non-commissioned armed forces officers -> 28\n",
      "Numerical and material recording clerks -> 29\n",
      "Other clerical support workers -> 30\n",
      "Personal care workers -> 31\n",
      "Personal service workers -> 32\n",
      "Production and specialized services managers -> 33\n",
      "Protective services workers -> 34\n",
      "Refuse workers and other elementary workers -> 35\n",
      "Sales workers -> 36\n",
      "Science and engineering associate professionals -> 37\n",
      "Science and engineering professionals -> 38\n",
      "Stationary plant and machine operators -> 39\n",
      "Street and related sales and service workers -> 40\n",
      "Subsistence farmers, fishers, hunters and gatherers -> 41\n",
      "Teaching professionals -> 42\n",
      "Unknown -> 43\n",
      "\n",
      "PUFC17_NATEM\n",
      "Different Employer -> 0\n",
      "Permanent Job -> 1\n",
      "Short-term -> 2\n",
      "Unknown -> 3\n",
      "\n",
      "PUFC23_PCLASS\n",
      "Employer -> 0\n",
      "Govt/Govt Corporation -> 1\n",
      "Private Establishment -> 2\n",
      "Private Household -> 3\n",
      "Self Employed -> 4\n",
      "Unknown -> 5\n",
      "With Pay (Family Owned Business) -> 6\n",
      "Without Pay (Family owned Business) -> 7\n",
      "\n",
      "PUFC41_WQTR\n",
      "No -> 0\n",
      "Unknown -> 1\n",
      "Yes -> 2\n",
      "\n",
      "PUFNEWEMPSTAT\n",
      "Employed -> 0\n",
      "Not in the Labor Force -> 1\n",
      "Unemployed -> 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns ## filter to object cols\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "## this encode the columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  \n",
    "\n",
    "## print the mappings \n",
    "for col, le in label_encoders.items():\n",
    "    mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print()\n",
    "    print(col)\n",
    "    for original, encoded in mapping.items():\n",
    "        print(f\"{original} -> {encoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign Target Value and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"PUFNEWEMPSTAT\"]).values\n",
    "y = df[\"PUFNEWEMPSTAT\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing Data: Standerdizes the features to have a mean of 0 and a standard deviation of 1, which helps the neural network converge faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split: Split data into 70% training and 30% testing\n",
    "- Stratify ensures the proportion of classes remains balanced between training and testing sets\n",
    "- Random State ensures reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to PyTorch Tensors for PyTorch processing \n",
    "- torch.float32 is sued for features,a nd torch.long is used for classification labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader Class\n",
    "- DataLoader: Efficiently manages batches for training\n",
    "- Shuffling : Ensures each epoch has a randomized set of samples to prevent the model from learning the order of data\n",
    "- Batching : Data is divided into smaller, managable chunks using the specified batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = X.shape[0]\n",
    "\n",
    "    def get_batch(self, mode='train'):\n",
    "        indices = np.arange(self.num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        X_shuffled = self.X[indices]\n",
    "        y_shuffled = self.y[indices]\n",
    "        X_batches = [X_shuffled[i:i + self.batch_size] for i in range(0, self.num_samples, self.batch_size)]\n",
    "        y_batches = [y_shuffled[i:i + self.batch_size] for i in range(0, self.num_samples, self.batch_size)]\n",
    "        return X_batches, y_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Class \n",
    "- Input Size: Number of Features (12)\n",
    "- Number of Classes : Employed, Unemployed, Not in the LAbor Force, Unknown\n",
    "- Hidden Layers : Customizable with size [64, 32]\n",
    "\n",
    "\n",
    "Building Layers\n",
    "- Linear Layers: Each layer has weights and biases\n",
    "- ReLU Activation: Common in deep learning, applying non-linearity to capture complex patterns\n",
    "\n",
    "\n",
    "Forward Pass\n",
    "- Network Pass: Passes input through all layers\n",
    "- Softmax: Copnverts oputput logits to probabilities, making it suitable for multi-class classficiation\n",
    "\n",
    "\n",
    "Prediction\n",
    "- Argmax: Chooses the class with the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, list_hidden, activation_function='relu'):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = []\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        # Input to first hidden layer\n",
    "        self.layers.append(nn.Linear(input_size, list_hidden[0]))\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(len(list_hidden) - 1):\n",
    "            self.layers.append(nn.ReLU() if activation_function == 'relu' else nn.Sigmoid())\n",
    "            self.layers.append(nn.Linear(list_hidden[i], list_hidden[i+1]))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.append(nn.ReLU() if activation_function == 'relu' else nn.Sigmoid())\n",
    "        self.layers.append(nn.Linear(list_hidden[-1], num_classes))\n",
    "\n",
    "        self.network = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x), torch.softmax(self.network(x), dim=1)\n",
    "\n",
    "    def predict(self, probabilities):\n",
    "        return torch.argmax(probabilities, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Initialization : Initializes the nueral network with the specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 12\n",
    "num_classes = 3\n",
    "list_hidden = [5,10 ]\n",
    "activation_function = 'relu'\n",
    "\n",
    "model = NeuralNetwork(input_size, num_classes, list_hidden, activation_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.8522,  0.3465, -0.6710, -0.3757, -0.0995, -0.4198,  0.3021,  0.6761,\n",
      "         -0.1282, -0.0941,  0.2008, -0.0966],\n",
      "        [-0.3136,  1.5479,  0.1381,  0.1886, -0.0201, -0.3294,  0.2168, -0.0121,\n",
      "          0.0888, -0.4473, -0.0136,  0.2231],\n",
      "        [-0.0536,  0.1635, -0.0434, -0.0828, -0.0176,  0.3802, -0.0199, -0.4563,\n",
      "          0.5402, -0.4951, -0.0128,  0.6300],\n",
      "        [-0.5134,  0.0615,  1.0749, -0.0631, -0.9233,  0.3119, -0.2927, -0.4202,\n",
      "          0.1599, -0.3731, -0.0431, -0.1092],\n",
      "        [-1.0158, -0.6505, -0.0346, -0.4954, -0.0652, -0.6214,  0.1501,  0.6570,\n",
      "         -0.4784,  0.0783, -0.0988,  0.2947]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2188,  0.1144,  1.8802,  0.7432, -0.4836], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].weight)\n",
    "\n",
    "print(model.layers[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and Optimizer\n",
    "- CrossEntropyLoss: Suitable for Classification tasks with multiple classes\n",
    "- Adam Optimizer: Efficient gradient descent with adaptive learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop\n",
    "- Epochs: Iterates over the entire dataset multiple times -- start with 50\n",
    "- Froward Pass: Computes predictions\n",
    "- Loss Calculation: MEasures error using CrossEntropyLoss\n",
    "- Backward Pass: Updates weights using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.1754, Val Loss: 0.0962\n",
      "Validation loss improved, saving model...\n",
      "Epoch [2/100], Train Loss: 0.0954, Val Loss: 0.0941\n",
      "Validation loss improved, saving model...\n",
      "Epoch [3/100], Train Loss: 0.0942, Val Loss: 0.0939\n",
      "Validation loss improved, saving model...\n",
      "Epoch [4/100], Train Loss: 0.0936, Val Loss: 0.0929\n",
      "Validation loss improved, saving model...\n",
      "Epoch [5/100], Train Loss: 0.0932, Val Loss: 0.0928\n",
      "Validation loss improved, saving model...\n",
      "Epoch [6/100], Train Loss: 0.0928, Val Loss: 0.0928\n",
      "Validation loss improved, saving model...\n",
      "Epoch [7/100], Train Loss: 0.0925, Val Loss: 0.0918\n",
      "Validation loss improved, saving model...\n",
      "Epoch [8/100], Train Loss: 0.0920, Val Loss: 0.0944\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [9/100], Train Loss: 0.0920, Val Loss: 0.0920\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [10/100], Train Loss: 0.0919, Val Loss: 0.0912\n",
      "Validation loss improved, saving model...\n",
      "Epoch [11/100], Train Loss: 0.0918, Val Loss: 0.0911\n",
      "Validation loss improved, saving model...\n",
      "Epoch [12/100], Train Loss: 0.0915, Val Loss: 0.0916\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [13/100], Train Loss: 0.0914, Val Loss: 0.0919\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [14/100], Train Loss: 0.0913, Val Loss: 0.0911\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [15/100], Train Loss: 0.0911, Val Loss: 0.0913\n",
      "No improvement for 4/10 epochs.\n",
      "Epoch [16/100], Train Loss: 0.0911, Val Loss: 0.0903\n",
      "Validation loss improved, saving model...\n",
      "Epoch [17/100], Train Loss: 0.0908, Val Loss: 0.0913\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [18/100], Train Loss: 0.0907, Val Loss: 0.0906\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [19/100], Train Loss: 0.0907, Val Loss: 0.0902\n",
      "Validation loss improved, saving model...\n",
      "Epoch [20/100], Train Loss: 0.0907, Val Loss: 0.0917\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [21/100], Train Loss: 0.0904, Val Loss: 0.0907\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [22/100], Train Loss: 0.0904, Val Loss: 0.0909\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [23/100], Train Loss: 0.0905, Val Loss: 0.0898\n",
      "Validation loss improved, saving model...\n",
      "Epoch [24/100], Train Loss: 0.0903, Val Loss: 0.0899\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [25/100], Train Loss: 0.0899, Val Loss: 0.0899\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [26/100], Train Loss: 0.0896, Val Loss: 0.0899\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [27/100], Train Loss: 0.0895, Val Loss: 0.0904\n",
      "No improvement for 4/10 epochs.\n",
      "Epoch [28/100], Train Loss: 0.0895, Val Loss: 0.0895\n",
      "Validation loss improved, saving model...\n",
      "Epoch [29/100], Train Loss: 0.0895, Val Loss: 0.0887\n",
      "Validation loss improved, saving model...\n",
      "Epoch [30/100], Train Loss: 0.0892, Val Loss: 0.0890\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [31/100], Train Loss: 0.0895, Val Loss: 0.0887\n",
      "Validation loss improved, saving model...\n",
      "Epoch [32/100], Train Loss: 0.0894, Val Loss: 0.0889\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [33/100], Train Loss: 0.0892, Val Loss: 0.0886\n",
      "Validation loss improved, saving model...\n",
      "Epoch [34/100], Train Loss: 0.0893, Val Loss: 0.0888\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [35/100], Train Loss: 0.0893, Val Loss: 0.0886\n",
      "Validation loss improved, saving model...\n",
      "Epoch [36/100], Train Loss: 0.0891, Val Loss: 0.0904\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [37/100], Train Loss: 0.0889, Val Loss: 0.0887\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [38/100], Train Loss: 0.0890, Val Loss: 0.0901\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [39/100], Train Loss: 0.0890, Val Loss: 0.0884\n",
      "Validation loss improved, saving model...\n",
      "Epoch [40/100], Train Loss: 0.0891, Val Loss: 0.0884\n",
      "Validation loss improved, saving model...\n",
      "Epoch [41/100], Train Loss: 0.0891, Val Loss: 0.0886\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [42/100], Train Loss: 0.0889, Val Loss: 0.0886\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [43/100], Train Loss: 0.0891, Val Loss: 0.0884\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [44/100], Train Loss: 0.0889, Val Loss: 0.0889\n",
      "No improvement for 4/10 epochs.\n",
      "Epoch [45/100], Train Loss: 0.0889, Val Loss: 0.0887\n",
      "No improvement for 5/10 epochs.\n",
      "Epoch [46/100], Train Loss: 0.0889, Val Loss: 0.0896\n",
      "No improvement for 6/10 epochs.\n",
      "Epoch [47/100], Train Loss: 0.0889, Val Loss: 0.0885\n",
      "No improvement for 7/10 epochs.\n",
      "Epoch [48/100], Train Loss: 0.0888, Val Loss: 0.0883\n",
      "Validation loss improved, saving model...\n",
      "Epoch [49/100], Train Loss: 0.0889, Val Loss: 0.0888\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [50/100], Train Loss: 0.0888, Val Loss: 0.0881\n",
      "Validation loss improved, saving model...\n",
      "Epoch [51/100], Train Loss: 0.0888, Val Loss: 0.0881\n",
      "Validation loss improved, saving model...\n",
      "Epoch [52/100], Train Loss: 0.0886, Val Loss: 0.0888\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [53/100], Train Loss: 0.0888, Val Loss: 0.0880\n",
      "Validation loss improved, saving model...\n",
      "Epoch [54/100], Train Loss: 0.0886, Val Loss: 0.0891\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [55/100], Train Loss: 0.0886, Val Loss: 0.0880\n",
      "Validation loss improved, saving model...\n",
      "Epoch [56/100], Train Loss: 0.0886, Val Loss: 0.0881\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [57/100], Train Loss: 0.0886, Val Loss: 0.0886\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [58/100], Train Loss: 0.0885, Val Loss: 0.0883\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [59/100], Train Loss: 0.0886, Val Loss: 0.0881\n",
      "No improvement for 4/10 epochs.\n",
      "Epoch [60/100], Train Loss: 0.0887, Val Loss: 0.0883\n",
      "No improvement for 5/10 epochs.\n",
      "Epoch [61/100], Train Loss: 0.0886, Val Loss: 0.0879\n",
      "Validation loss improved, saving model...\n",
      "Epoch [62/100], Train Loss: 0.0885, Val Loss: 0.0881\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [63/100], Train Loss: 0.0885, Val Loss: 0.0878\n",
      "Validation loss improved, saving model...\n",
      "Epoch [64/100], Train Loss: 0.0885, Val Loss: 0.0883\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [65/100], Train Loss: 0.0884, Val Loss: 0.0880\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [66/100], Train Loss: 0.0885, Val Loss: 0.0901\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [67/100], Train Loss: 0.0884, Val Loss: 0.0887\n",
      "No improvement for 4/10 epochs.\n",
      "Epoch [68/100], Train Loss: 0.0885, Val Loss: 0.0878\n",
      "Validation loss improved, saving model...\n",
      "Epoch [69/100], Train Loss: 0.0885, Val Loss: 0.0878\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [70/100], Train Loss: 0.0884, Val Loss: 0.0876\n",
      "Validation loss improved, saving model...\n",
      "Epoch [71/100], Train Loss: 0.0884, Val Loss: 0.0883\n",
      "No improvement for 1/10 epochs.\n",
      "Epoch [72/100], Train Loss: 0.0883, Val Loss: 0.0880\n",
      "No improvement for 2/10 epochs.\n",
      "Epoch [73/100], Train Loss: 0.0884, Val Loss: 0.0892\n",
      "No improvement for 3/10 epochs.\n",
      "Epoch [74/100], Train Loss: 0.0884, Val Loss: 0.0883\n",
      "No improvement for 4/10 epochs.\n",
      "Epoch [75/100], Train Loss: 0.0884, Val Loss: 0.0888\n",
      "No improvement for 5/10 epochs.\n",
      "Epoch [76/100], Train Loss: 0.0885, Val Loss: 0.0878\n",
      "No improvement for 6/10 epochs.\n",
      "Epoch [77/100], Train Loss: 0.0883, Val Loss: 0.0884\n",
      "No improvement for 7/10 epochs.\n",
      "Epoch [78/100], Train Loss: 0.0885, Val Loss: 0.0880\n",
      "No improvement for 8/10 epochs.\n",
      "Epoch [79/100], Train Loss: 0.0883, Val Loss: 0.0881\n",
      "No improvement for 9/10 epochs.\n",
      "Epoch [80/100], Train Loss: 0.0884, Val Loss: 0.0881\n",
      "No improvement for 10/10 epochs.\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "epochs = 100\n",
    "patience = 10\n",
    "best_val_loss = float('inf')\n",
    "wait = 0\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(X_train_tensor, y_train_tensor, batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_batches, y_batches = dataloader.get_batch(mode='train')\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model.forward(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(X_batches)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_batches, val_labels = dataloader.get_batch(mode='val')\n",
    "    val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in zip(val_batches, val_labels):\n",
    "            val_outputs, _ = model.forward(X_val)\n",
    "            loss = criterion(val_outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_batches)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        wait = 0\n",
    "        print(\"Validation loss improved, saving model...\")\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        wait += 1\n",
    "        print(f\"No improvement for {wait}/{patience} epochs.\")\n",
    "\n",
    "    if wait >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict \n",
    "- model.eval(): Ensures dropout and batch normalization are disabled.\n",
    "- torch.no_grad(): Prevents unnecessary gradient calculations.\n",
    "- model.forward(X): Gets the raw output from the model (logits or probabilities).\n",
    "- torch.argmax(outputs, dim=1): Converts the output to class predictions by selecting the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs, _ = model.forward(X)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "    return predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "- Accuracy Calculation: Compares predictions to actual labels.\n",
    "- classification_report(): Provides a detailed breakdown of Precision, Recall, and F1-score for each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
    "    # Predict on test data\n",
    "    y_pred = predict(model, X_test_tensor)\n",
    "\n",
    "    # Convert tensors to numpy for evaluation\n",
    "    y_test_np = y_test_tensor.numpy()\n",
    "    y_pred_np = y_pred.numpy()\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test_np, y_pred_np)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test_np, y_pred_np))\n",
    "    print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0,  ..., 1, 0, 0])\n",
      "Accuracy: 0.9584\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20526\n",
      "           1       0.87      0.95      0.91      5894\n",
      "           2       0.58      0.30      0.40      1253\n",
      "\n",
      "    accuracy                           0.96     27673\n",
      "   macro avg       0.81      0.75      0.77     27673\n",
      "weighted avg       0.95      0.96      0.95     27673\n",
      "\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Predict on test data\n",
    "predictions = predict(model, X_test_tensor)\n",
    "print(predictions)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, X_test_tensor, y_test_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
